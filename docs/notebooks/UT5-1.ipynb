{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 ‚Äî Investigaci√≥n: Conceptos Fundamentales de Prefect\n",
    "\n",
    "## 1.1 Tasks en Prefect\n",
    "\n",
    "### 1. ¬øQu√© es una Task en Prefect?\n",
    "Una **Task** es una unidad de trabajo dentro de un pipeline. B√°sicamente es una funci√≥n que hace algo espec√≠fico (extraer datos, transformar, validar, guardar, etc.) y Prefect la puede monitorear, reintentar si falla y registrar su estado.  \n",
    "La usamos cuando queremos dividir el pipeline en pasos claros y reutilizables.\n",
    "\n",
    "### 2. ¬øQu√© significa que las Tasks sean ‚Äúlazily evaluated‚Äù?  \n",
    "Significa que **no se ejecutan cuando las llam√°s en el c√≥digo**, sino reci√©n cuando corre el *flow*.  \n",
    "Prefect primero arma el grafo de dependencias (el DAG) y despu√©s ejecuta todo en el orden correcto.  \n",
    "Esto permite que el pipeline sea m√°s eficiente y flexible.\n",
    "\n",
    "### 3. ¬øQu√© son los Task States?  \n",
    "Son los **estados** que indican en qu√© etapa est√° una Task durante su ejecuci√≥n.\n",
    "\n",
    "| Estado      | ¬øCu√°ndo ocurre? |\n",
    "|-------------|------------------|\n",
    "| **PENDING** | La task est√° lista, pero todav√≠a no empez√≥ a ejecutarse. |\n",
    "| **RUNNING** | La task se est√° ejecutando en ese momento. |\n",
    "| **COMPLETED** | Termin√≥ bien sin errores. |\n",
    "| **FAILED** | Fall√≥ durante la ejecuci√≥n. |\n",
    "| **RETRYING** | Fall√≥ pero tiene reintentos configurados y volver√° a intentarse. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Flows en Prefect\n",
    "\n",
    "### 1. ¬øCu√°l es la diferencia entre un Flow y una Task? ¬øPor qu√© necesitamos ambos?\n",
    "\n",
    "Un **Flow** es el ‚Äúpipeline completo‚Äù: coordina y ordena todos los pasos.  \n",
    "Una **Task** es un paso individual dentro de ese pipeline.\n",
    "\n",
    "Necesitamos ambos porque:\n",
    "- Las Tasks dividen el trabajo en partes peque√±as y reutilizables.\n",
    "- El Flow decide el orden, manejo de dependencias y ejecuci√≥n general.\n",
    "\n",
    "### 2. ¬øQu√© es un \"subflow\"? ¬øCu√°ndo ser√≠a √∫til usar subflows?\n",
    "\n",
    "Un **subflow** es un Flow que se llama desde dentro de otro Flow.  \n",
    "Sirve para modularizar el pipeline, reutilizar partes completas o separar l√≥gicas que se repiten (por ejemplo: `extract_and_validate()`).\n",
    "\n",
    "### 3. ¬øC√≥mo maneja Prefect las dependencias entre tasks? (DAG impl√≠cito)\n",
    "\n",
    "Prefect crea el DAG **autom√°ticamente**:  \n",
    "cuando una Task usa el resultado de otra (`transform(extract())`), Prefect detecta esa dependencia sin que la declares expl√≠citamente.\n",
    "\n",
    "As√≠ arma un **DAG impl√≠cito**, ejecutando cada Task en el orden correcto seg√∫n lo que necesita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Investigaci√≥n avanzada: Results y Caching\n",
    "\n",
    "### 1. ¬øQu√© es el \"result persistence\"? ¬øPor qu√© es importante en pipelines de datos?\n",
    "\n",
    "Es la capacidad de Prefect de **guardar y recuperar resultados de tasks** (por ejemplo en archivos, S3, bases de datos o memoria).\n",
    "\n",
    "Es importante porque:\n",
    "- Evita recalcular pasos costosos\n",
    "- Permite reanudar un pipeline que fall√≥\n",
    "- Facilita debugging y auditor√≠a\n",
    "- Mejora reproducibilidad\n",
    "\n",
    "### 2. ¬øC√≥mo funciona el caching en Prefect? ¬øQu√© par√°metro usar√≠an para cachear el resultado de una task?\n",
    "\n",
    "Prefect evita ejecutar una task si ya tiene un **resultado v√°lido en cach√©** generado con los mismos par√°metros.\n",
    "\n",
    "Se habilita usando:\n",
    "- `cache_expiration` (tiempo de validez)\n",
    "- **o** `cache_key_fn` (clave de cach√© personalizada)\n",
    "\n",
    "### 3. ¬øQu√© es una `cache_key_fn`? Den un ejemplo de cu√°ndo la usar√≠an.\n",
    "\n",
    "Es una funci√≥n que genera **manual y expl√≠citamente** la clave de cach√© de una task.  \n",
    "Sirve cuando no quer√©s que el cach√© dependa de *todos* los par√°metros, sino solo de algunos.\n",
    "\n",
    "**Ejemplo:**  \n",
    "Cachear una extracci√≥n diaria usando solo la fecha:\n",
    "\n",
    "```python\n",
    "def key_fn(_, date):\n",
    "    return f\"extract-{date}\"\n",
    "```\n",
    "\n",
    "As√≠, si ya extrajiste los datos del d√≠a 2025-10-01, no se vuelve a ejecutar la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 ‚Äî Dise√±o Conceptual\n",
    "\n",
    "## 2.1 Arquitectura del escenario\n",
    "\n",
    "**Escenario elegido:** Transacciones diarias de un e-commerce.\n",
    "\n",
    "| Rol                 | ¬øQui√©n ser√≠a en su escenario? |\n",
    "|--------------------|-------------------------------|\n",
    "| Business data owner | Equipo de ventas del e-commerce |\n",
    "| Data engineers      | Equipo de ingenier√≠a de datos que mantiene el pipeline ETL |\n",
    "| Data consumers      | Analistas de negocio y dashboards de reporting |\n",
    "\n",
    "## 2.2 Tipo de pipeline\n",
    "\n",
    "- **Tipo elegido (batch/streaming):** Batch  \n",
    "- **Justificaci√≥n:**  \n",
    "  Las ventas se procesan de manera diaria. No necesitamos procesamiento en tiempo real, y el enfoque batch es m√°s eficiente para an√°lisis agregados, validaci√≥n de calidad de datos y reintentos controlados. Adem√°s, simplifica el dise√±o del ETL y reduce costos operativos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3 ‚Äî Implementaci√≥n del Pipeline Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entorno configurado correctamente\n",
      "üìÖ Fecha: 2025-12-02 21:31\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Setup\n",
    "\n",
    "# Instalaci√≥n de Prefect\n",
    "!pip install -q prefect pandas\n",
    "\n",
    "# Importar librer√≠as\n",
    "from prefect import flow, task\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Entorno configurado correctamente\")\n",
    "print(f\"üìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Implementar Tasks\n",
    "\n",
    "# === TASK 1: EXTRACT ===\n",
    "# Usamos tags y log_prints para que todo quede registrado en Prefect\n",
    "\n",
    "@task(tags=[\"extract\"], log_prints=True)\n",
    "def extract_data():\n",
    "    \"\"\"\n",
    "    Extrae datos de la fuente.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_rows = 100\n",
    "\n",
    "    data = {\n",
    "        'fecha': pd.date_range(start='2024-01-01', periods=n_rows, freq='D'),\n",
    "        'producto': np.random.choice(['A', 'B', 'C', 'D'], n_rows),\n",
    "        'cantidad': np.random.randint(1, 50, n_rows),\n",
    "        'precio_unitario': np.random.uniform(10, 100, n_rows).round(2),\n",
    "        'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], n_rows)\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"üì• Extra√≠dos {len(df)} registros\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# === TASK 2: TRANSFORM ===\n",
    "@task(tags=[\"transform\"], log_prints=True)\n",
    "def transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica transformaciones a los datos.\n",
    "    \"\"\"\n",
    "    df['total'] = df['cantidad'] * df['precio_unitario']\n",
    "\n",
    "    df['ticket_size'] = pd.cut(\n",
    "        df['total'],\n",
    "        bins=[0, 100, 500, float('inf')],\n",
    "        labels=['small', 'medium', 'large']\n",
    "    )\n",
    "\n",
    "    print(f\"üîÑ Transformados {len(df)} registros\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# === TASK 3: LOAD ===\n",
    "@task(tags=[\"load\"], log_prints=True, retries=2, retry_delay_seconds=3)\n",
    "def load_data(df: pd.DataFrame, output_path: str = \"output.csv\"):\n",
    "    \"\"\"\n",
    "    Carga los datos al destino final.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"üíæ Guardados {len(df)} registros en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:24.571 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8364</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:24.571 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8364\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.206 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'intelligent-swift'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'intelligent-swift'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'ETL Pipeline Ventas'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.206 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'intelligent-swift'\u001b[0m - Beginning flow run\u001b[35m 'intelligent-swift'\u001b[0m for flow\u001b[1;35m 'ETL Pipeline Ventas'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.273 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-daa' - üì• Extra√≠dos 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.273 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-daa' - üì• Extra√≠dos 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.293 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-daa' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.293 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-daa' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.372 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-c9c' - üîÑ Transformados 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.372 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-c9c' - üîÑ Transformados 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.390 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-c9c' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.390 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-c9c' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.428 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-49f' - üíæ Guardados 100 registros en output.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.428 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-49f' - üíæ Guardados 100 registros en output.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.446 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-49f' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.446 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-49f' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.447 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'intelligent-swift'</span> - \n",
       "‚úÖ Pipeline ETL completado exitosamente!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.447 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'intelligent-swift'\u001b[0m - \n",
       "‚úÖ Pipeline ETL completado exitosamente!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:35:26.453 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'intelligent-swift'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:35:26.453 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'intelligent-swift'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.3 Implementar Flow\n",
    " \n",
    "# === FLOW: Orquestador del pipeline ===\n",
    "\n",
    "@flow(name=\"ETL Pipeline Ventas\", log_prints=True)\n",
    "def etl_flow():\n",
    "    \"\"\"\n",
    "    Flow principal que orquesta las tasks ETL.\n",
    "    \"\"\"\n",
    "    df_raw = extract_data()\n",
    "    df_clean = transform_data(df_raw)\n",
    "    load_data(df_clean)\n",
    "\n",
    "    print(\"\\n‚úÖ Pipeline ETL completado exitosamente!\")\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "# === EJECUTAR ===\n",
    "if __name__ == \"__main__\":\n",
    "    resultado = etl_flow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Preguntas de observaci√≥n\n",
    "\n",
    "### 1. ¬øQu√© informaci√≥n muestra Prefect en los logs? Copien un fragmento y expl√≠quenlo.\n",
    "\n",
    "**Fragmento real de mis logs:**\n",
    "\n",
    "INFO | Flow run 'intelligent-swift' - Beginning flow run 'ETL Pipeline Ventas'\n",
    "INFO | Task run 'extract_data-daa' - üì• Extra√≠dos 100 registros\n",
    "INFO | Task run 'extract_data-daa' - Finished in state Completed()\n",
    "INFO | Task run 'transform_data-c9c' - üîÑ Transformados 100 registros\n",
    "INFO | Task run 'transform_data-c9c' - Finished in state Completed()\n",
    "INFO | Task run 'load_data-49f' - üíæ Guardados 100 registros en output.csv\n",
    "INFO | Task run 'load_data-49f' - Finished in state Completed()\n",
    "INFO | Flow run 'intelligent-swift' - Finished in state Completed()\n",
    "\n",
    "\n",
    "**Explicaci√≥n:**  \n",
    "Los logs muestran cada paso del pipeline: el inicio del flow, la ejecuci√≥n de cada task, los prints internos y el estado final de cada una (`Completed`). Tambi√©n muestra cu√°ntos registros se procesaron y cu√°ndo finaliza todo el ETL. Es informaci√≥n clave para monitorear el pipeline y detectar errores.\n",
    "\n",
    "### 2. ¬øEn qu√© orden se ejecutaron las tasks? ¬øC√≥mo lo infiere Prefect?\n",
    "\n",
    "El orden fue:\n",
    "\n",
    "1. `extract_data`\n",
    "2. `transform_data`\n",
    "3. `load_data`\n",
    "\n",
    "Prefect lo infiere autom√°ticamente porque construye un **DAG impl√≠cito**:  \n",
    "cada task recibe como par√°metro la salida de la anterior, por lo que entiende que esas dependencias deben respetarse y ejecuta en ese orden sin que uno lo tenga que especificar manualmente.\n",
    "\n",
    "### 3. ¬øQu√© pasar√≠a si una task falla? ¬øQu√© estados tendr√≠a el flow?\n",
    "\n",
    "Si una task falla:\n",
    "\n",
    "- La task entra en estado **FAILED** o **RETRYING** si tiene reintentos.\n",
    "- Todas las tasks que dependan de ella no se ejecutan.\n",
    "- El flow completo termina en **FAILED** o **CRASHED**, seg√∫n el tipo de error.\n",
    "\n",
    "Prefect detiene autom√°ticamente el pipeline para evitar resultados inconsistentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4 ‚Äî Investigaci√≥n: Funcionalidades Avanzadas\n",
    "\n",
    "## 4.1 Retries y manejo de errores\n",
    "\n",
    "### 1. ¬øQu√© par√°metros controlan los retries?\n",
    "\n",
    "| Par√°metro | Descripci√≥n | Valor por defecto |\n",
    "|----------|-------------|-------------------|\n",
    "| `retries` | N√∫mero de veces que se intentar√° repetir la task si falla. | `0` |\n",
    "| `retry_delay_seconds` | Tiempo fijo entre reintentos. | `0` |\n",
    "| `retry_jitter_factor` | Factor que agrega aleatoriedad al delay para evitar colisiones. | `0` |\n",
    "\n",
    "### 2. ¬øQu√© es exponential backoff?\n",
    "\n",
    "Exponential backoff es una estrategia donde cada reintento espera el doble que el anterior  \n",
    "(1s ‚Üí 2s ‚Üí 4s ‚Üí 8s‚Ä¶).  \n",
    "Sirve para no saturar APIs/servidores cuando hay fallos repetidos.\n",
    "\n",
    "En Prefect se puede lograr usando `retry_delay_seconds` junto con `retry_jitter_factor`,  \n",
    "o implementando un delay creciente dentro de la l√≥gica de la task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(retries=3, retry_delay_seconds=2, log_prints=True)\n",
    "def extract_data_with_retry():\n",
    "    \"\"\"Task con reintentos autom√°ticos.\"\"\"\n",
    "    # Simular fallo aleatorio para probar retries\n",
    "    if np.random.random() < 0.5:\n",
    "        raise Exception(\"Error simulado de conexi√≥n\")\n",
    "    return \"datos extra√≠dos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:47:59.421 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'rare-honeybee'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'rare-honeybee'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'test-retry-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:47:59.421 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'rare-honeybee'\u001b[0m - Beginning flow run\u001b[35m 'rare-honeybee'\u001b[0m for flow\u001b[1;35m 'test-retry-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:47:59.447 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data_with_retry-b4b' - Task run failed with exception: Exception('Error simulado de conexi√≥n') - Retry 1/3 will start 2 second(s) from now\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:47:59.447 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data_with_retry-b4b' - Task run failed with exception: Exception('Error simulado de conexi√≥n') - Retry 1/3 will start 2 second(s) from now\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:48:01.454 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data_with_retry-b4b' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:48:01.454 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data_with_retry-b4b' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">21:48:01.471 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'rare-honeybee'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "21:48:01.471 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'rare-honeybee'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'datos extra√≠dos'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@flow\n",
    "def test_retry_flow():\n",
    "    return extract_data_with_retry()\n",
    "\n",
    "test_retry_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Caching de resultados\n",
    "\n",
    "### 1. ¬øQu√© es `cache_expiration`? ¬øC√≥mo se especifica?\n",
    "\n",
    "`cache_expiration` define cu√°nto tiempo es v√°lido el resultado cacheado de una task.\n",
    "Si la task corre nuevamente dentro de ese tiempo, Prefect no la re-ejecuta y devuelve el resultado almacenado.\n",
    "\n",
    "Se especifica usando un `timedelta`, por ejemplo:\n",
    "\n",
    "```python\n",
    "@task(cache_expiration=timedelta(minutes=10))\n",
    "```\n",
    "\n",
    "### 2. ¬øCu√°ndo es √∫til cachear una task? Den 2 ejemplos de su escenario.\n",
    "\n",
    "**Ejemplo 1:**\n",
    "Cuando la extracci√≥n de datos es costosa (por ejemplo, acceder a una API lenta o pagada).\n",
    "\n",
    "**Ejemplo 2:**\n",
    "Cuando los datos no cambian todo el tiempo (por ejemplo, ventas del d√≠a que solo se actualizan una vez por d√≠a).\n",
    "\n",
    "### 3. ¬øQu√© pasa si los inputs de la task cambian? ¬øSe usa el cache?\n",
    "\n",
    "**No.**\n",
    "Si los inputs de la task cambian, Prefect genera una clave de cach√© distinta y **vuelve a ejecutar la task.**\n",
    "El cache solo se usa cuando los par√°metros de entrada y el tiempo de expiraci√≥n coinciden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# Implementaci√≥n del caching en la task de extracci√≥n\n",
    "@task(cache_expiration=timedelta(minutes=5), log_prints=True)\n",
    "def extract_data_cached():\n",
    "    \"\"\"Task con caching ‚Äî no re-ejecuta si ya corri√≥ recientemente.\"\"\"\n",
    "    print(\"‚è≥ Ejecutando extracci√≥n (esto NO deber√≠a aparecer si est√° cacheado)\")\n",
    "    return extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.473 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'versatile-goldfish'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'versatile-goldfish'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'test-cache-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.473 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'versatile-goldfish'\u001b[0m - Beginning flow run\u001b[35m 'versatile-goldfish'\u001b[0m for flow\u001b[1;35m 'test-cache-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.493 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data_cached-19a' - ‚è≥ Ejecutando extracci√≥n (esto NO deber√≠a aparecer si est√° cacheado)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.493 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data_cached-19a' - ‚è≥ Ejecutando extracci√≥n (esto NO deber√≠a aparecer si est√° cacheado)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.516 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-4b1' - üì• Extra√≠dos 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.516 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-4b1' - üì• Extra√≠dos 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.535 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-4b1' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.535 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-4b1' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.536 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data_cached-19a' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.536 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data_cached-19a' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.544 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'versatile-goldfish'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.544 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'versatile-goldfish'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.578 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'ruddy-urchin'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'ruddy-urchin'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'test-cache-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.578 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'ruddy-urchin'\u001b[0m - Beginning flow run\u001b[35m 'ruddy-urchin'\u001b[0m for flow\u001b[1;35m 'test-cache-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.597 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data_cached-ebc' - ‚è≥ Ejecutando extracci√≥n (esto NO deber√≠a aparecer si est√° cacheado)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.597 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data_cached-ebc' - ‚è≥ Ejecutando extracci√≥n (esto NO deber√≠a aparecer si est√° cacheado)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.617 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-a59' - üì• Extra√≠dos 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.617 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-a59' - üì• Extra√≠dos 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.635 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-a59' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.635 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-a59' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.637 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data_cached-ebc' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.637 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data_cached-ebc' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">22:01:29.644 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'ruddy-urchin'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "22:01:29.644 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'ruddy-urchin'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>producto</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>precio_unitario</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>C</td>\n",
       "      <td>18</td>\n",
       "      <td>93.67</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>D</td>\n",
       "      <td>26</td>\n",
       "      <td>82.73</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>44</td>\n",
       "      <td>67.01</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>C</td>\n",
       "      <td>34</td>\n",
       "      <td>88.43</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>82.33</td>\n",
       "      <td>Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>B</td>\n",
       "      <td>13</td>\n",
       "      <td>69.72</td>\n",
       "      <td>Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>B</td>\n",
       "      <td>32</td>\n",
       "      <td>10.46</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>D</td>\n",
       "      <td>7</td>\n",
       "      <td>24.47</td>\n",
       "      <td>Este</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>B</td>\n",
       "      <td>22</td>\n",
       "      <td>59.39</td>\n",
       "      <td>Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>A</td>\n",
       "      <td>28</td>\n",
       "      <td>72.27</td>\n",
       "      <td>Este</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha producto  cantidad  precio_unitario region\n",
       "0  2024-01-01        C        18            93.67  Oeste\n",
       "1  2024-01-02        D        26            82.73  Norte\n",
       "2  2024-01-03        A        44            67.01  Norte\n",
       "3  2024-01-04        C        34            88.43  Oeste\n",
       "4  2024-01-05        C        10            82.33  Norte\n",
       "..        ...      ...       ...              ...    ...\n",
       "95 2024-04-05        B        13            69.72    Sur\n",
       "96 2024-04-06        B        32            10.46  Oeste\n",
       "97 2024-04-07        D         7            24.47   Este\n",
       "98 2024-04-08        B        22            59.39    Sur\n",
       "99 2024-04-09        A        28            72.27   Este\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@flow\n",
    "def test_cache_flow():\n",
    "    return extract_data_cached()\n",
    "\n",
    "test_cache_flow()\n",
    "test_cache_flow()   # segunda ejecuci√≥n ‚Üí deber√≠a evitar la extracci√≥n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Logging personalizado\n",
    "\n",
    "### 1. ¬øC√≥mo se accede al logger de Prefect dentro de una task?\n",
    "\n",
    "Usando la funci√≥n:\n",
    "\n",
    "```python\n",
    "from prefect import get_run_logger\n",
    "logger = get_run_logger()\n",
    "```\n",
    "\n",
    "### 2. ¬øQu√© niveles de log soporta Prefect? Listen al menos 4.\n",
    "\n",
    "1. logger.debug()\n",
    "2. logger.info()\n",
    "3. logger.warning()\n",
    "4. logger.error()\n",
    "\n",
    "### 3. ¬øC√≥mo configurar√≠an el nivel de log para ver m√°s detalle?\n",
    "\n",
    "En el decorador de la task o del flow, usando:\n",
    "\n",
    "```python\n",
    "@flow(log_prints=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import get_run_logger\n",
    "\n",
    "@task\n",
    "def transform_data_with_logging(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Task con logging estructurado.\"\"\"\n",
    "    \n",
    "    logger = get_run_logger()   # obtener el logger de Prefect\n",
    "\n",
    "    logger.info(f\"Iniciando transformaci√≥n de {len(df)} registros\")  # nivel info\n",
    "\n",
    "    df['total'] = df['cantidad'] * df['precio_unitario']\n",
    "\n",
    "    # Log de estad√≠sticas\n",
    "    logger.info(f\"Total ventas: ${df['total'].sum():,.2f}\")  # nivel info\n",
    "    logger.info(f\"Detalle por regi√≥n: {df.groupby('region')['total'].sum().to_dict()}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Concurrencia y paralelismo\n",
    "\n",
    "### 1. ¬øQu√© es un Task Runner? ¬øCu√°l es el default?\n",
    "\n",
    "Un **Task Runner** es el componente que define c√≥mo se ejecutan las tasks dentro de un flow:\n",
    "- secuencialmente,\n",
    "- en paralelo,\n",
    "- con hilos,\n",
    "- con procesos, etc.\n",
    "\n",
    "El **default** en Prefect 2.x es: `ConcurrentTaskRunner`.\n",
    "\n",
    "### 2. ¬øQu√© Task Runners ofrece Prefect? Describan al menos 2:\n",
    "\n",
    "| Task Runner | ¬øCu√°ndo usarlo? |\n",
    "|----------|-------------|\n",
    "| `ConcurrentTaskRunner` | Para ejecutar tasks en paralelo usando threads. Ideal para I/O (APIs, lectura/escritura). |\n",
    "| `SequentialTaskRunner` | Para ejecutar tasks una por una. √ötil para debugging o pipelines sin paralelismo. |\n",
    "\n",
    "### 3. ¬øC√≥mo ejecutar√≠an tasks en paralelo? Investiguen .submit() y .map().\n",
    "\n",
    "**.submit():**\n",
    "Ejecuta una task as√≠ncrona, devolviendo un Future.\n",
    "Permite lanzar varias tasks a la vez sin esperar que terminen.\n",
    "\n",
    "**.map():**\n",
    "Ejecuta la misma task varias veces en paralelo, una por cada elemento de una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow, task\n",
    "from prefect.task_runners import ConcurrentTaskRunner\n",
    "\n",
    "@task\n",
    "def process_region(region: str, df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Procesa datos de una regi√≥n espec√≠fica.\"\"\"\n",
    "    df_region = df[df['region'] == region]\n",
    "    return {\n",
    "        'region': region,\n",
    "        'total': df_region['total'].sum(),\n",
    "        'count': len(df_region)\n",
    "    }\n",
    "\n",
    "@flow(task_runner=ConcurrentTaskRunner())  # usar concurrencia real\n",
    "def etl_flow_parallel():\n",
    "    df_raw = extract_data()\n",
    "    df_clean = transform_data(df_raw)\n",
    "\n",
    "    # Procesar cada regi√≥n en paralelo\n",
    "    regiones = ['Norte', 'Sur', 'Este', 'Oeste']\n",
    "    futures = [process_region.submit(r, df_clean) for r in regiones]  # m√©todo async\n",
    "\n",
    "    # Esperar resultados\n",
    "    results = [f.result() for f in futures]  # obtener resultados\n",
    "\n",
    "    print(f\"üìä Resultados por regi√≥n: {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 5 ‚Äî Investigaci√≥n: Deployments y Scheduling\n",
    "\n",
    "## 5.1 Conceptos de Deployment\n",
    "\n",
    "### 1. ¬øQu√© es un Deployment en Prefect? ¬øCu√°l es la diferencia entre un Flow y un Deployment?\n",
    "\n",
    "Un **Deployment** es una *configuraci√≥n ejecutable* de un Flow: incluye c√≥mo, cu√°ndo y d√≥nde se ejecuta.\n",
    "El **Flow** es el *c√≥digo Python* que define la l√≥gica del pipeline.\n",
    "El **Deployment** es la *instalaci√≥n* del flujo en Prefect, con par√°metros como:\n",
    "\n",
    "* scheduling\n",
    "* work pool\n",
    "* versi√≥n\n",
    "* par√°metros del flow\n",
    "* infraestructura usada\n",
    "* almacenamiento\n",
    "\n",
    "En resumen:\n",
    "*Flow = l√≥gica*\n",
    "*Deployment = ejecuci√≥n programada y versionada del flow*\n",
    "\n",
    "### 2. ¬øQu√© es un Work Pool? ¬øPara qu√© sirve?\n",
    "\n",
    "Un **Work Pool** es un grupo l√≥gico que administra *qu√© infraestructura* se usar√° para ejecutar los deployments.\n",
    "Sirve para:\n",
    "\n",
    "* organizar distintos entornos (dev, staging, prod)\n",
    "* conectar Workers con Flows\n",
    "* administrar colas de ejecuci√≥n\n",
    "* separar cargas de trabajo por equipo o tipo de tarea\n",
    "\n",
    "Es, b√°sicamente, el ‚Äúpuente‚Äù entre los deployments y los workers.\n",
    "\n",
    "### 3. ¬øQu√© es un Worker? ¬øC√≥mo se relaciona con el Work Pool?\n",
    "\n",
    "Un **Worker** es un proceso que:\n",
    "\n",
    "* se registra en un Work Pool\n",
    "* escucha tareas pendientes\n",
    "* toma deployments y los ejecuta\n",
    "\n",
    "La relaci√≥n es:\n",
    "\n",
    "*Deployment ‚Üí Work Pool ‚Üí Worker ‚Üí Ejecuta el Flow*\n",
    "\n",
    "El Deployment se env√≠a al Work Pool, el Work Pool lo pone en cola, y los Workers conectados lo levantan y ejecutan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Scheduling\n",
    "\n",
    "### 1. ¬øQu√© tipos de schedules soporta Prefect?\n",
    "\n",
    "Describan al menos 3:\n",
    "\n",
    "| Tipo de Schedule     | Descripci√≥n                                                                             | Ejemplo                                               |\n",
    "| -------------------- | --------------------------------------------------------------------------------------- | ----------------------------------------------------- |\n",
    "| **CronSchedule**     | Usa sintaxis cron para ejecutar flows en horarios repetitivos.                          | `\"0 6 * * *\"` ‚Üí todos los d√≠as a las 6 AM             |\n",
    "| **IntervalSchedule** | Ejecuta el flow cada cierto intervalo fijo.                                             | `timedelta(hours=1)` ‚Üí cada 1 hora                    |\n",
    "| **RRuleSchedule**    | Usa reglas RFC 5545 para horarios complejos (frecuencias, excepciones, m√∫ltiples d√≠as). | ‚ÄúCada lunes y mi√©rcoles a las 9 AM, excepto feriados‚Äù |\n",
    "\n",
    "\n",
    "### 2. ¬øC√≥mo expresar√≠an \"ejecutar todos los d√≠as a las 6 AM\" en cron?\n",
    "\n",
    "```cron\n",
    "0 6 * * *\n",
    "```\n",
    "\n",
    "### 3. ¬øQu√© es un `RRuleSchedule`? ¬øCu√°ndo lo usar√≠an sobre cron?\n",
    "\n",
    "`RRuleSchedule` implementa las reglas RFC 5545 (iCalendar), permitiendo programaciones **mucho m√°s complejas** que cron:\n",
    "\n",
    "* horarios irregulares\n",
    "* m√∫ltiples d√≠as espec√≠ficos\n",
    "* intervalos combinados\n",
    "* exclusiones (no correr feriados)\n",
    "* reglas encadenadas\n",
    "\n",
    "Lo usar√≠a en lugar de cron cuando necesito l√≥gica de calendario m√°s avanzada que cron *no puede expresar f√°cilmente*, como:\n",
    "\n",
    "> ‚ÄúCorrer el pipeline s√≥lo los d√≠as h√°biles del mes, a las 9 AM, excluyendo feriados que se definan aparte.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Crear un Deployment (conceptual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object sync_compatible.<locals>.coroutine_wrapper.<locals>.ctx_call at 0x1611609a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Completar bas√°ndose en la documentaci√≥n de Deployments\n",
    "# https://docs.prefect.io/latest/concepts/deployments/\n",
    "\n",
    "# Opci√≥n 1: Usando serve() - m√°s simple\n",
    "# if __name__ == \"__main__\":\n",
    "#     etl_flow.serve(\n",
    "#         name=\"etl-diario-ecommerce\",  # nombre del deployment\n",
    "#         cron=\"0 6 * * *\",  # schedule en formato cron\n",
    "#         tags=[\"etl\", \"ecommerce\"],  # tags para organizaci√≥n\n",
    "#     )\n",
    "\n",
    "# Opci√≥n 2: Usando deploy() - m√°s control\n",
    "etl_flow.deploy(\n",
    "    name=\"etl-diario-ecommerce\",\n",
    "    work_pool_name=\"local-pool\",\n",
    "    cron=\"0 6 * * *\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 6 ‚Äî Extensi√≥n DataOps\n",
    "\n",
    "## Opci√≥n A ‚Äî Validaci√≥n con logging estructurado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task, get_run_logger\n",
    "\n",
    "@task(\n",
    "    retries=3,                   # La task se reintenta 3 veces si falla\n",
    "    retry_delay_seconds=2        # Espera 2 segundos entre reintentos\n",
    ")\n",
    "def validate_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Valida la calidad de los datos usando logging estructurado.\n",
    "    Incluye validaciones b√°sicas y reporta errores antes de continuar.\n",
    "    \"\"\"\n",
    "\n",
    "    logger = get_run_logger()\n",
    "    errors = []\n",
    "\n",
    "    # --- Inicio del proceso de validaci√≥n ---\n",
    "    logger.info(\"üîç Iniciando validaci√≥n de datos\")\n",
    "\n",
    "    # 1) Validaci√≥n: DataFrame vac√≠o\n",
    "    if len(df) == 0:\n",
    "        logger.error(\"‚ùå DataFrame vac√≠o detectado\")\n",
    "        errors.append(\"DataFrame vac√≠o\")\n",
    "\n",
    "    # 2) Validaci√≥n: valores nulos por columna\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        logger.warning(f\"‚ö†Ô∏è Valores nulos encontrados: {null_counts.to_dict()}\")\n",
    "\n",
    "    # 3) Validaci√≥n: columnas esperadas\n",
    "    columnas_esperadas = {\"fecha\", \"producto\", \"cantidad\", \"precio_unitario\", \"region\", \"total\"}\n",
    "    columnas_actuales = set(df.columns)\n",
    "\n",
    "    if columnas_esperadas - columnas_actuales:\n",
    "        faltantes = columnas_esperadas - columnas_actuales\n",
    "        logger.error(f\"‚ùå Columnas faltantes: {faltantes}\")\n",
    "        errors.append(f\"Columnas faltantes: {faltantes}\")\n",
    "\n",
    "    # Si hubo errores ‚Üí cortar ejecuci√≥n\n",
    "    if errors:\n",
    "        raise ValueError(f\"Validaci√≥n fallida: {errors}\")\n",
    "\n",
    "    # --- Fin de validaci√≥n ---\n",
    "    logger.info(\"‚úÖ Validaci√≥n exitosa\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¬øQu√© hace esta task?**\n",
    "\n",
    "La task `validate_data()` implementa reglas de calidad de datos y usa **logging estructurado de Prefect** para registrar:\n",
    "* mensajes informativos (`logger.info`)\n",
    "* advertencias (`logger.warning`)\n",
    "* errores (`logger.error`)\n",
    "\n",
    "Esto permite auditar qu√© pas√≥ con los datos y facilita debugging.\n",
    "\n",
    "**Se agregan:**\n",
    "\n",
    "```python\n",
    "retries=3\n",
    "retry_delay_seconds=2\n",
    "```\n",
    "\n",
    "porque en pipelines reales los fallos suelen ser temporales (e.g., un archivo no lleg√≥ todav√≠a).\n",
    "Con estos par√°metros la task:\n",
    "* intenta 3 veces\n",
    "* espera 2 segundos entre cada intento\n",
    "\n",
    "**Validaciones implementadas**\n",
    "1. DataFrame vac√≠o\n",
    "2. Valores nulos\n",
    "3. Columnas faltantes\n",
    "4. Si hay errores ‚Üí se corta el flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 7 ‚Äî Reflexi√≥n y Conexi√≥n con DataOps (5 min)¬∂\n",
    "\n",
    "## 7.1 Conceptos de Prefect\n",
    "\n",
    "### 1. ¬øC√≥mo ayuda Prefect a implementar el principio de \"Observabilidad\" de DataOps?\n",
    "\n",
    "Prefect registra autom√°ticamente cada etapa del pipeline: estados, logs, retries, tiempos de ejecuci√≥n y errores.\n",
    "Esto permite **ver qu√© pas√≥, d√≥nde fall√≥ y por qu√©**, logrando trazabilidad completa sin agregar infraestructura extra.\n",
    "En DataOps, esto es clave para detectar problemas r√°pido y medir la salud del pipeline.\n",
    "\n",
    "### 2. ¬øC√≥mo ayuda el caching a la \"Reproducibilidad\"?\n",
    "\n",
    "El caching garantiza que, si los inputs no cambiaron, la task devuelve **exactamente el mismo resultado**.\n",
    "Esto elimina variaciones accidentales, acelera re-ejecuciones y permite reconstruir outputs pasados de manera consistente.\n",
    "En resumen: **mismos datos ‚Üí mismo resultado**, siempre.\n",
    "\n",
    "### 3. ¬øC√≥mo conectan los Deployments con \"CI/CD para datos\"?\n",
    "\n",
    "Un Deployment convierte un flow en un artefacto versionado, ejecutable y schedulable.\n",
    "Esto permite integrarlo en pipelines de CI/CD: cuando se hace un commit, el deployment se actualiza, se testea y se despliega autom√°ticamente.\n",
    "Es la forma en que Prefect permite **automatizar, versionar y publicar** pipelines como si fueran software.\n",
    "\n",
    "## 7.2 Comparaci√≥n con alternativas\n",
    "\n",
    "### 1. ¬øQu√© diferencias hay entre Prefect y Apache Airflow? Mencionen al menos 2.\n",
    "\n",
    "Diferencia 1: Prefect usa un DAG **impl√≠cito**, construido seg√∫n el orden del c√≥digo; Airflow requiere declarar DAGs de forma expl√≠cita y m√°s verbosa.\n",
    "\n",
    "Diferencia 2: Prefect tiene **mejor manejo de estados, retries y logs** sin configuraci√≥n adicional.\n",
    "Airflow requiere m√°s setup y es m√°s r√≠gido en su arquitectura.\n",
    "\n",
    "### 2. ¬øQu√© es Dagster? ¬øEn qu√© se diferencia de Prefect?\n",
    "\n",
    "Dagster es un framework de orquestaci√≥n enfocado en data assets: permite definir datasets como entidades con dependencias expl√≠citas.\n",
    "Prefect, en cambio, se centra en **flows y tasks**, con mucha m√°s flexibilidad y menos estructura obligatoria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
