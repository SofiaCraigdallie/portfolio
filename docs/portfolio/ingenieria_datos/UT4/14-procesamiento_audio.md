---
title: "ğŸ”Š UT4 Â· PrÃ¡ctica 14 â€” Preprocesamiento de Audio"
date: 2025-11-25
---

# ğŸ”Š Preprocesamiento de Audio  

---

# ğŸŒ Contexto

Esta prÃ¡ctica pertenece a la **Unidad TemÃ¡tica 4: Geodatos y SeÃ±ales**, en la cual se incorpora el tratamiento de **datos no tabulares**, especÃ­ficamente **audio digital**.  
El objetivo central fue comprender cÃ³mo trabajar con **representaciones en el dominio del tiempo**, el **dominio de la frecuencia** y representaciones **tiempoâ€“frecuencia** como los **espectrogramas**.

Se trabajÃ³ con un audio del dataset **UrbanSound8K**, aplicando:

- carga y visualizaciÃ³n de waveform,  
- STFT y espectrogramas de Mel,  
- normalizaciÃ³n y estandarizaciÃ³n,  
- adiciÃ³n de ruido,  
- mÃ©tricas espectrales,  
- anÃ¡lisis exploratorio de la distribuciÃ³n del dataset,  
- augmentations: *pitch shift* y *time stretch*.

Esta prÃ¡ctica conecta procesamiento de seÃ±ales con *feature engineering* para modelos de audio.

---

# ğŸ¯ Objetivos

- Comprender cÃ³mo se representa una seÃ±al de audio digital.  
- Construir visualizaciones en los dominios **tiempo**, **frecuencia** y **tiempoâ€“frecuencia**.  
- Aplicar **preprocesamiento**: normalizaciÃ³n, estandarizaciÃ³n y adiciÃ³n de ruido.  
- Implementar **mÃ©tricas espectrales dinÃ¡micas** (centroid, rolloff, bandwidth).  
- Realizar **augmentations supervisados**: pitch shift y time stretch.  
- Analizar la distribuciÃ³n del dataset UrbanSound8K.

---

# ğŸ“¦ Dataset

| Aspecto | DescripciÃ³n |
|--------|-------------|
| **Fuente** | UrbanSound8K |
| **Tipo** | Archivos `.wav` mono o estÃ©reo |
| **Muestreo** | 44.1 kHz (segÃºn archivo) |
| **Estructura** | 10 folders (â€œfold1â€ â€¦ â€œfold10â€) para validaciÃ³n cruzada |
| **Tarea** | ClasificaciÃ³n de eventos sonoros (sirenas, perros, disparos, etc.) |

---

# ğŸ”Š RepresentaciÃ³n en el dominio del tiempo

![Waveform mono](../../../assets/img/audio_waveform.png)

**Figura 1:** Waveform del audio seleccionado.  
Se observan pulsos de energÃ­a bien definidos y silencios intermedios, tÃ­pico de eventos aislados.

---

# ğŸ›ï¸ Espectrogramas: STFT y Mel

![STFT y Mel](../../../assets/img/audio_stft_mel.png)

**Figura 2:**  
- **Arriba:** STFT: muestra cÃ³mo evoluciona la energÃ­a en cada frecuencia.  
- **Abajo:** Espectrograma de Mel: compresiÃ³n perceptual del eje de frecuencia.

Ambos realzan claramente los tres eventos de impacto + el bloque final del sonido mÃ¡s sostenido.

---

# ğŸ”§ NormalizaciÃ³n y estandarizaciÃ³n

![NormalizaciÃ³n](../../../assets/img/audio_standardized.png)

**Figura 3:** ComparaciÃ³n entre la seÃ±al original y la estandarizada.  
La forma general se preserva, pero la escala queda normalizada, Ãºtil para modelos neuronales.

---

# ğŸšï¸ Espectrogramas normalizado vs original

![Espectrograma original](../../../assets/img/audio_spectrogram_original.png)

![Espectrograma normalizado](../../../assets/img/audio_spectrogram_original_standardized.png)

**Figura 4 y Figura 5:** La estandarizaciÃ³n reduce la amplitud dinÃ¡mica y hace mÃ¡s homogÃ©neo el espectrograma.

---

# ğŸ”¥ AdiciÃ³n de ruido blanco (SNRâ‰ˆ10dB)

![Ruido blanco](../../../assets/img/audio_white_noise.png)

**Figura 5:** El ruido eleva el piso espectral, Ãºtil para robustecer modelos de clasificaciÃ³n.

---

# ğŸ“ˆ MÃ©tricas espectrales dinÃ¡micas

![MÃ© tricas dinÃ¡micas](../../../assets/img/audio_spectral_metrics.png)

**Figura 6:**  
- **Centroid:** â€œcentro de masaâ€ de las frecuencias.  
- **Rolloff:** frecuencia por debajo de la cual se acumula el 85 % de la energÃ­a.  
- **Bandwidth:** ancho del espectro.  

Se ven picos coincidentes con los eventos del audio.

---

# ğŸ“Š ExploraciÃ³n del dataset UrbanSound8K

![Cantidad por fold](../../../assets/img/audio_folds.png)

**Figura 7:** DistribuciÃ³n de audios por folder.  
Los folds estÃ¡n relativamente balanceados (800â€“1000 audios cada uno).

---

# ğŸµ Augmentations

## ğŸ”¼ Pitch shift (+2 semitonos)

![Pitch shift](../../../assets/img/audio_pitch_shift.png)

**Figura 8:** El contenido armÃ³nico se desplaza hacia arriba, sin alterar la forma temporal.

---

## â³ Time Stretch (0.9x)

![Time Stretch](../../../assets/img/audio_time_stretch.png)

**Figura 9:** El audio se comprime ligeramente en el tiempo, manteniendo relaciones tonales.  
Useful para variaciÃ³n temporal sin alterar pitch.

---

# ğŸ§  Resultados y discusiÃ³n

| Aspecto | Hallazgo | InterpretaciÃ³n |
|--------|----------|----------------|
| **Forma de onda** | Pulsos bien definidos | Audio con eventos discretos y silencios marcados |
| **Espectrograma STFT** | EnergÃ­a concentrada en bajas frecuencias | Propio de golpes/impactos fÃ­sicos |
| **Mel-Spectrogram** | Estructuras mÃ¡s claras y compactas | RepresentaciÃ³n perceptual â†’ mejor para modelos |
| **NormalizaciÃ³n** | Escala controlada | Facilita convergencia del modelo |
| **Ruido blanco** | Piso espectral elevado | Augmentation Ãºtil para robustez |
| **Pitch shift** | Desplazamiento armÃ³nico | InyecciÃ³n de variabilidad tonal |
| **Time stretch** | CompresiÃ³n temporal | Aumenta diversidad temporal |

> **Insight general:**  
> Trabajar en dominios complementarios (tiempo, frecuencia y tiempoâ€“frecuencia) permite extraer caracterÃ­sticas que ningÃºn dominio por sÃ­ solo revela.  
> El preprocesamiento determina la calidad de las features y el rendimiento final del modelo de audio.

---

# ğŸ”— ConexiÃ³n con otras unidades

- **UT1:** VisualizaciÃ³n y anÃ¡lisis exploratorio, ahora aplicado a seÃ±ales.  
- **UT2:** Calidad de datos â†’ ruido, normalizaciÃ³n, amplitud.  
- **UT3:** Feature Engineering â†’ mÃ©tricas espectrales y espectrogramas usados como features.  
- **UT5:** Augmentations + pipelines reproducibles para datasets de audio.

---

# ğŸ§© ReflexiÃ³n final

ComprendÃ­ cÃ³mo una seÃ±al de audio es mucho mÃ¡s que su waveform.  
El pasaje al dominio de frecuencia y sus variantes perceptuales (Mel) abre la puerta a modelos robustos y explicables.

La combinaciÃ³n de preprocesamiento + augmentations es clave para modelos de clasificaciÃ³n de audio, especialmente cuando hay pocos datos.  
Esta prÃ¡ctica me dio un entendimiento completo del pipeline inicial en proyectos de *Machine Listening*.

---

# ğŸ§° Stack tÃ©cnico

**Lenguaje:** Python  
**LibrerÃ­as:** Librosa Â· NumPy Â· Matplotlib Â· Pandas  
**Conceptos:** Waveform Â· STFT Â· MelSpectrogram Â· NormalizaciÃ³n Â· Ruido Â· Pitch Shift Â· Time Stretch

---

# Evidencias

### ğŸ“ [Notebook](../../../notebooks/UT4-3.ipynb)

---

# ğŸ“š Referencias

- UT4 â€” Audio: <https://juanfkurucz.com/ucu-id/ut4/14-audio/>  
- [Librosa documentation](https://librosa.org/  )
- [UrbanSound8K dataset](https://urbansounddataset.weebly.com/)