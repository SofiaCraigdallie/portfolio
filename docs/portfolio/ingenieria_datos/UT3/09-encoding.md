---
title: "ğŸ§© Encoding Avanzado â€” Adult Income (Census)"
date: 2025-10-27
---

# ğŸ§© Encoding Avanzado â€” Adult Income (Census)

---

# ğŸŒ Contexto

Esta prÃ¡ctica forma parte de la **Unidad TemÃ¡tica 3: Feature Engineering** y estÃ¡ enfocada en **comparar codificadores categÃ³ricos** y su impacto en el rendimiento, la dimensionalidad y la interpretabilidad de modelos de *Machine Learning*.  
Se trabajÃ³ con el dataset **Adult Income (US Census, 1994)** para predecir si el ingreso anual es **>50K**. El Ã©nfasis estuvo en **seleccionar el encoding adecuado segÃºn la cardinalidad** y en **evitar *data leakage*** en tÃ©cnicas guiadas por el target.

---

# ğŸ¯ Objetivos

- Diagnosticar **cardinalidad** y riesgos de **explosiÃ³n dimensional**.
- Implementar y evaluar **Label, One-Hot, Target** y **pipelines ramificados** con `ColumnTransformer`.
- Medir **Accuracy, AUC-ROC, F1, tiempo y #features** como criterios de decisiÃ³n.
- Analizar **feature importance** y discutir **impacto Ã©tico/interpretabilidad**.
- Explorar variantes: **Frequency, Ordinal, Leave-One-Out, Binary** y **smoothing**.

---

# ğŸ“¦ Dataset

| Aspecto | DescripciÃ³n |
|---|---|
| **Fuente** | UCI ML Repository â€” Adult (Census Income) |
| **Tarea** | ClasificaciÃ³n binaria (`target`: `income >50K`) |
| **TamaÃ±o** | 32â€¯561 registros, 16 columnas (8 categÃ³ricas, 6 numÃ©ricas + 2 auxiliares) |
| **Cardinalidad** | Baja: `workclass`, `marital-status`, `relationship`, `race`, `sex` Â· Media: `education` (16), `occupation` (15), `native-country` (42) Â· Alta (>50): **ninguna** |
| **Nota** | Se limpiÃ³ espacios en categorÃ­as, se creÃ³ `target` y se estratificÃ³ el *split*. |

---

# ğŸ§¹ Limpieza y preparaciÃ³n

1. **Carga + limpieza:** `strip()` en categÃ³ricas, remover filas con `?`.  
2. **Target binario:** `target = (income == '>50K').astype(int)`.  
3. **SelecciÃ³n numÃ©ricas:** `age`, `fnlwgt`, `education-num`, `capital-gain`, `capital-loss`, `hours-per-week`.  
4. **DiagnÃ³stico de cardinalidad:** riesgo de **one-hot = 11.8Ã—** columnas si se aplicara a todas.

---

# ğŸ” AnÃ¡lisis de cardinalidad

![Cardinalidad de variables categÃ³ricas](../../../assets/img/cardinalidad_variables_categÃ³ricas.png)

**Figura 1.** DiagnÃ³stico de cardinalidad por variable. Se observa que la mayorÃ­a de las columnas son de baja cardinalidad (â‰¤10), aunque `education`, `occupation` y `native-country` se ubican en rango medio (11â€“50), lo que justifica usar encodings distintos segÃºn el tipo.

> **ConclusiÃ³n:** aplicar *One-Hot* a todas las categÃ³ricas no es viable. Se optÃ³ por:  
> - *Label Encoding* para comparativa base,  
> - *One-Hot* para baja cardinalidad,  
> - *Target Encoding* para media/alta cardinalidad (en datasets futuros),  
> - y una *Pipeline Ramificada* que combine estos enfoques.

---

# ğŸ§ª Experimentos

## 1) Label Encoding (todas las categÃ³ricas)
- **Modelo:** `RandomForestClassifier(100)`  
- **Resultados:**  
  - **Accuracy:** **0.8632** Â· **AUC:** **0.9101** Â· **F1:** **0.6931**  
  - **Tiempo:** 0.45â€¯s Â· **#Features:** 14

## 2) Oneâ€‘Hot (solo baja cardinalidad)
- CategÃ³ricas: `['workclass','marital-status','relationship','race','sex']`  
- **Resultados:** Accuracy 0.8483 Â· AUC 0.8995 Â· F1 0.6633 Â· Tiempo 0.43â€¯s Â· **#Features:** 30

## 3) Target Encoding (alta/mediana cardinalidad)
- En este *split* no hubo columnas >50; se evaluÃ³ *target* para referencia.  
- **Resultados:** Accuracy 0.8021 Â· AUC 0.8272 Â· F1 0.5538 Â· Tiempo 0.43â€¯s Â· **#Features:** 6

## 4) Pipeline ramificado (ColumnTransformer)
- **Ramas:** Oneâ€‘Hot(baja) + Target(alta, 0 en este caso) + `StandardScaler`(numÃ©ricas).  
- **Resultados:** Accuracy 0.8485 Â· AUC 0.8996 Â· F1 0.6646 Â· Tiempo 0.44â€¯s Â· **#Features:** 30

---

# ğŸ“Š ComparaciÃ³n de mÃ©todos

| Encoding | Accuracy | AUC-ROC | F1-Score | Tiempo (s) | #Features |
|---|---:|---:|---:|---:|---:|
| **Label Encoding** | **0.8632** | **0.9101** | **0.6931** | 0.45 | **14** |
| Oneâ€‘Hot (low card) | 0.8483 | 0.8995 | 0.6633 | 0.43 | 30 |
| Target (high card) | 0.8021 | 0.8272 | 0.5538 | **0.43** | **6** |
| Branched Pipeline | 0.8485 | 0.8996 | 0.6646 | 0.44 | 30 |

![ComparaciÃ³n de encoding por mÃ©todo](../../../assets/img/comparaciÃ³n_imp_mÃ©todo.png)

**Figura 2.** ComparaciÃ³n de los cuatro esquemas de codificaciÃ³n (Label, One-Hot, Target y Pipeline Ramificado). Se observa que Label Encoding logra el mejor equilibrio entre rendimiento y complejidad, mientras que One-Hot y Pipeline aumentan la dimensionalidad sin mejoras notables.


![ComparaciÃ³n de mÃ©tricas y trade-offs entre mÃ©todos de encoding](../../../assets/img/mÃ©todos_mÃ©tricas.png)

**Figura 3.** ComparaciÃ³n visual de mÃ©tricas y trade-offs. Label Encoding y Pipeline mantienen alta exactitud con tiempos bajos. Target Encoding reduce la dimensionalidad, pero sacrifica rendimiento global.

---

# ğŸ” Explicabilidad â€” Feature Importance (Pipeline)

![Importancia de features del modelo Random Forest](../../../assets/img/feature_importance_random_forest.png)

**Figura 4.** Variables mÃ¡s relevantes segÃºn el modelo Random Forest. `fnlwgt`, `age`, `education-num`, `capital-gain` y `hours-per-week` lideran la predicciÃ³n, mientras que algunas categÃ³ricas *one-hot* (`marital-status_Married-civ-spouse`, `sex_Male`, `workclass_Private`) aportan contexto adicional.

**Importancia por tipo de feature:**
- **NumÃ©ricas:** 76.7 % del total (6 variables).  
- **One-Hot:** 23.3 % (24 variables).  
> Esto muestra que la **estructura cuantitativa del censo domina** la predicciÃ³n del ingreso, aunque las categÃ³ricas ayudan a refinar segmentos sociales.

![Importancia total y promedio por tipo de feature](../../../assets/img/features_codificadas.png)

**Figura 5.** ComparaciÃ³n de la importancia total y promedio por tipo de variable. Las numÃ©ricas dominan tanto en peso total como en relevancia promedio; las categÃ³ricas aportan granularidad, pero con menor influencia individual.

---

# ğŸ§ª DesafÃ­os y variantes adicionales

- **Frequency(native-country):** Acc 0.8081 Â· AUC 0.8311 Â· F1 0.5645 Â· 7 feats.  
  - Ãštil, bajo riesgo si se calcula **solo en train**.  
- **Ordinal(education):** Acc 0.8019 Â· AUC 0.8272 Â· F1 0.5546 Â· 7 feats.  
  - Preserva orden; beneficia a Ã¡rboles/lineales cuando hay escala.  
- **LOO(native-country):** Acc 0.7640 Â· AUC 0.6732 Â· F1 0.0576 Â· 7 feats.  
  - Reduce fuga usando media que **excluye** el propio registro; aquÃ­ no rindiÃ³.  
- **Binary(native-country):** Acc 0.8062 Â· AUC 0.8315 Â· F1 0.5572 Â· 12 feats (â‰ˆlogâ‚‚ 42 â‰ˆ 6 bits).  
  - Compacta alta cardinalidad sin usar el target.  
- **Target smoothing:** `sâˆˆ(1, 10, 100, 1000)` â†’ AUC â‰ˆ 0.828â€“0.832; **s=100** levemente mejor.  
  - `s` interpola media global â†” media por categorÃ­a; alto `s` estabiliza clases raras.

---

# ğŸ§  Resultados y discusiÃ³n

| Hallazgo | ImplicaciÃ³n |
|-----------|-------------|
| **Label Encoding** domina en mÃ©tricas con baja dimensionalidad | Recomendado con **modelos de Ã¡rboles** cuando no hay cardinalidades extremas. |
| **One-Hot (baja)** y **Pipeline (mixto)** logran rendimientos similares | La expansiÃ³n de columnas **no mejora el rendimiento**, solo la interpretabilidad. |
| **Target/LOO** no superaron alternativas | Ãštiles en **alta cardinalidad** o con regularizaciÃ³n/CV; no aplican en este dataset. |
| **Predictores numÃ©ricos** concentran la mayor explicaciÃ³n | La carga horaria, capital y edad son las variables que mÃ¡s condicionan el ingreso. |

---

# ğŸ”— ConexiÃ³n con otras unidades

- **UT1 (EDA):** el diagnÃ³stico de cardinalidad y leakage nace del anÃ¡lisis exploratorio.  
- **UT2 (Calidad & Ã‰tica):** fairness: evitar que el modelo refuerce sesgos (sexo/estado civil).  
- **UT4 (Especiales):** pipelines reproducibles y escalables; *deploy* sin fugas.  

---

# ğŸ§© ReflexiÃ³n final

El tipo de encoding **define el espacio de hipÃ³tesis del modelo**.  
En este caso, **Ã¡rboles + Label Encoding** ofrecieron el mejor rendimiento con bajo costo computacional, mientras que *One-Hot* y *Target* solo justifican su uso ante cardinalidades extremas.  

ComprendÃ­ que elegir el encoding correcto no es solo una decisiÃ³n tÃ©cnica, sino tambiÃ©n Ã©tica: debe garantizar **equidad, interpretabilidad y reproducibilidad**.  
En producciÃ³n, optarÃ­a por un **`ColumnTransformer` ramificado**, activando la rama *target* solo si aparecen variables de alta cardinalidad y monitoreando mÃ©tricas de equidad.

---

# ğŸ§° Stack tÃ©cnico

Python Â· pandas Â· NumPy Â· scikitâ€‘learn Â· category_encoders Â· matplotlib  
**Conceptos:** cardinalidad, *data leakage*, *target smoothing*, pipelines, *feature importance*

---

# Evidencias

### ğŸ“ [Notebook](../../../notebooks/UT3-2.ipynb)

---

# ğŸ“š Referencias

- PrÃ¡ctica: <https://juanfkurucz.com/ucu-id/ut3/09-encoding-avanzado-assignment/>  
- UCI Adult: Dua, D. & Graff, C. (2019). *UCI ML Repository* â€” Adult.  
- Scikitâ€‘learn: *ColumnTransformer*, *Pipelines*, *OneHotEncoder*.  
- `category_encoders`: *Target*, *Binary* encoders.