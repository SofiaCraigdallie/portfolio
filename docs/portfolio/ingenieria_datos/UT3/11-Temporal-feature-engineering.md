---
title: "â±ï¸ UT3 Â· PrÃ¡ctica 11 â€” Temporal Feature Engineering con Pandas"
date: 2025-11-09
---

# â±ï¸ Temporal Feature Engineering con Pandas

---

# ğŸŒ Contexto

Esta prÃ¡ctica de la **Unidad TemÃ¡tica 3 (Feature Engineering)** trabaja **datos transaccionales de eâ€‘commerce** para construir **features temporales** con `pandas` evitando **data leakage**. El foco estÃ¡ en: **lags**, **rolling/expanding windows**, **agregaciones por usuario**, **features cÃ­clicas**, **variables externas** y **validaciÃ³n temporal**.

> Regla de oro: **ordenar por tiempo y agrupar por usuario** antes de calcular cualquier feature temporal.

---

# ğŸ¯ Objetivos

- Implementar **lag features** con `.groupby().shift()` (sin leakage).
- Calcular **rolling** y **expanding** windows con exclusiÃ³n explÃ­cita del presente.
- Armar **RFM** (Recency, Frequency, Monetary) y **agregaciones por usuario**.
- Agregar **calendar features** con **encoding cÃ­clico** (sin/cos) y **variables externas** simuladas.
- DiseÃ±ar **validaciÃ³n basada en tiempo** (`TimeSeriesSplit`) y comparar **modelo base vs. temporal**.
- Redactar **conclusiones** y **chequeos de leakage**.

---

# ğŸ“¦ Dataset

| Aspecto | DescripciÃ³n |
|---|---|
| **Fuente** | Kaggle â€” *Online Retail (2010â€“2011)* |
| **Archivo** | `OnlineRetail.csv` |
| **Estructura** | Transacciones (eventos irregulares, muchas Ã³rdenes por usuario) |
| **Target** | `will_purchase_again`: indica si el usuario realiza una orden posterior. |

> Nota: AceptÃ¡ el dataset en Kaggle (join/accept) antes de descargar con API.

![Ã“rdenes semanales y dÃ­as entre Ã³rdenes](../../../assets/img/pedidos_semanales.png)

**Figura 1.** A la izquierda se observa la cantidad de Ã³rdenes Ãºnicas por semana.  
A la derecha, la distribuciÃ³n de dÃ­as entre Ã³rdenes, con una **mediana cercana a 28 dÃ­as**, lo que justifica la creaciÃ³n de *lags* y ventanas de 7, 30 y 90 dÃ­as.

---

# ğŸ”§ MetodologÃ­a general

El proceso se estructurÃ³ en **siete etapas**, construyendo un pipeline reproducible:

1. **Limpieza:** se eliminaron Ã³rdenes canceladas, precios y cantidades no vÃ¡lidos, y se tipificaron fechas.  
2. **Nivel de orden:** se agregaron `cart_size` (tamaÃ±o del carrito) y `order_total` (gasto total).  
3. **Lags:** se calcularon variables `days_since_prior_lag_{1..3}` mediante `.shift()` agrupando por usuario.  
4. **Rolling / Expanding:** medias, desviaciones y sumas histÃ³ricas, siempre desplazadas una fila para evitar mirar al presente.  
5. **RFM + Ventanas:** mÃ©tricas de recencia, frecuencia y gasto, ademÃ¡s de ventanas de 7/30/90 dÃ­as (`orders_7d`, `spend_90d`, etc.).  
6. **Calendario y cÃ­clicas:** variables de dÃ­a, hora y mes transformadas con seno/coseno, junto con feriados del Reino Unido.  
7. **Externas:** variables econÃ³micas mensuales simuladas (`gdp_growth`, `unemployment_rate`, `confidence`), propagadas hacia adelante (*forward fill*) para evitar fugas temporales.

> El modelo base fue un **RandomForestClassifier** (`n_estimators=100`, `max_depth=10`, `random_state=42`).

---

# âš–ï¸ Resultados: modelo base vs modelo temporal

![AUC base vs temporal](../../../assets/img/auc_base_vs_temporal.png)

**Figura 2.** ComparaciÃ³n de AUC promedio entre modelos.  
El modelo con features temporales alcanzÃ³ un **AUC de 0.7277**, frente a **0.6615** del modelo base, lo que representa una **mejora del 10%**.  
Esta diferencia confirma que las variables derivadas del tiempo aportan seÃ±al predictiva real.

---

# ğŸ” Variables mÃ¡s relevantes

![Importancia de features temporales](../../../assets/img/feature_importance_temporal.png)

**Figura 3.** A la izquierda, las 25 variables mÃ¡s importantes segÃºn el modelo.  
A la derecha, la importancia acumulada por categorÃ­a.  
Destacan las **lags y ventanas mÃ³viles**, seguidas por las de **RFM** y **diversidad de productos**.  
Las variables de calendario y las externas econÃ³micas tuvieron menor impacto, aunque ayudaron a capturar estacionalidad.

---

# âœ… PrevenciÃ³n de leakage

Para garantizar que el modelo no accediera a datos del futuro:

- Todas las agregaciones histÃ³ricas se realizaron con **`.shift(1)`**.  
- Las **ventanas mÃ³viles y acumulativas** excluyen el registro actual.  
- Las **variables externas** usan solo informaciÃ³n previa (relleno hacia adelante).  
- Se utilizÃ³ **`TimeSeriesSplit`** para validar respetando el orden cronolÃ³gico.

---

# ğŸ§  Resultados y discusiÃ³n

| Hallazgo | Lectura |
|---|---|
| **AUC +0.066** | Las features temporales aportan seÃ±al real de recompra. |
| **Horizonte** | Las ventanas **de 90 dÃ­as** son mÃ¡s informativas que 7/30. |
| **CategorÃ­as** | **Lag/Window > RFM > Diversidad > Calendario/EconÃ³micas**. |
| **Robustez** | Gap trainâ€“CV razonable, sin indicios de fuga. |

> En un entorno productivo, implementarÃ­a un **pipeline diario** que regenere features solo con datos hasta la fecha de corte.  
> Para futuras versiones, extenderÃ­a con **Fourier features** para estacionalidad, **tendencias (slopes)** y validaciones tipo **walk-forward**.

---

# ğŸ”— ConexiÃ³n con otras unidades

- **UT2:** ReforcÃ© la importancia de datos limpios y consistentes en el tiempo antes de cualquier modelado.  
- **UT4:** Este ejercicio anticipa cÃ³mo construir pipelines de ETL reproducibles, donde las ventanas y agregaciones se regeneran automÃ¡ticamente cada dÃ­a.  
- **UT5:** Las mÃ©tricas (AUC y mejora del 10%) se vinculan con objetivos de negocio como retenciÃ³n y predicciÃ³n de churn.

---

# ğŸ§© ReflexiÃ³n final

Este ejercicio me ayudÃ³ a entender que las **features temporales son las mÃ¡s poderosas** para describir el comportamiento dinÃ¡mico de los usuarios.  
Las *lags* permiten detectar patrones de repeticiÃ³n, las *rolling windows* suavizan fluctuaciones y las mÃ©tricas *RFM* resumen la historia de cada cliente.

MÃ¡s allÃ¡ del rendimiento, aprendÃ­ la importancia de **respetar la secuencia temporal** y diseÃ±ar pipelines que sean **seguros frente a leakage**.  
El equilibrio entre informaciÃ³n Ãºtil y costo computacional es clave: las ventanas amplias son costosas, pero ofrecen una lectura mÃ¡s profunda del comportamiento.

---

# ğŸ§° Stack tÃ©cnico

**Python** Â· Pandas Â· NumPy Â· Scikit-learn Â· Matplotlib/Seaborn  
**Conceptos:** Lags Â· Rolling/Expanding Â· RFM Â· Ventanas 7/30/90d Â· Encoding cÃ­clico Â· `TimeSeriesSplit` Â· Leakage Prevention

---

# Evidencias

### ğŸ“ [Notebook](../../../notebooks/UT3-4.ipynb)

---

# ğŸ“š Referencias

- PrÃ¡ctica: <https://juanfkurucz.com/ucu-id/ut3/11-temporal-features-assignment/> 
- Kaggle API â€” https://www.kaggle.com/docs/api  
- Pandas Time Series â€” https://pandas.pydata.org/docs/user_guide/timeseries.html  
- TimeSeriesSplit â€” https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html  
- RandomForestClassifier â€” https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
