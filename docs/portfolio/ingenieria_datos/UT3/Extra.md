---
title: "ğŸ§ª UT3 Â· 03â€‘1 â€” Miniâ€‘Assignment: Feature Selection robusta vs PCA (Ames Housing)"
date: 2025-11-09
---

# ğŸ§ª UT3 Miniâ€‘Assignment: Feature Selection robusta vs PCA (Ames Housing)

> **Trabajo extra sin guÃ­a oficial.** Objetivo: diseÃ±ar y ejecutar un **experimento reproducible** que compare **reducciÃ³n por proyecciÃ³n (PCA)** vs **selecciÃ³n de variables** bajo **validaciÃ³n robusta**, incorporando **estabilidad** y **explicabilidad**.

---

# ğŸŒ Contexto

Dos estrategias para alta dimensionalidad en Ames: **PCA** (proyecciÃ³n) y **Feature Selection** (elecciÃ³n). El objetivo es medir **desempeÃ±o**, **explicabilidad** y **costo**, con **validaciÃ³n cruzada** y chequeos de **fuga de datos**.

---

# ğŸ¯ Objetivos

- Armar un **pipeline** (preproceso âœ selecciÃ³n/proyecciÃ³n âœ modelo) con `scikitâ€‘learn`.
- Evaluar **PCA** con distintos niveles de varianza acumulada (80/90/95%).
- Evaluar **FS** en modos *filter*, *wrapper*, *embedded* con una **grilla simple**.
- Medir **estabilidad de selecciÃ³n** por *bootstrapping* (frecuencia de inclusiÃ³n).
- Analizar **importancias/permutation importance** y **colinealidad residual**.
- Redactar una **discusiÃ³n** que justifique el â€œmejorâ€ enfoque.

---

# ğŸ“¦ Dataset

| Aspecto | DescripciÃ³n |
|---|---|
| **Fuente** | Kaggle â€” *House Prices: Advanced Regression Techniques* |
| **Target** | `SalePrice` (regresiÃ³n) |
| **Notas** | Nulos y variables categÃ³ricas con alta cardinalidad. |

---

# âš™ï¸ Setup

- `ColumnTransformer` con:
  - NumÃ©ricas â†’ `SimpleImputer(median)` + `StandardScaler`  
  - CategÃ³ricas â†’ `SimpleImputer(most_frequent)` + `OneHotEncoder(handle_unknown="ignore", sparse_output=False)`  
- Modelos/estimas: `LinearRegression`, `Lasso`, `RandomForestRegressor`.
- ValidaciÃ³n: `KFold(n_splits=5, shuffle=True, random_state=42)`.

---

# ğŸ§¹ Preprocesamiento

- Se elimina `Id` y se separa `SalePrice`.  
- Oneâ€‘Hot Encoding en categÃ³ricas; escalado estÃ¡ndar en numÃ©ricas.  
- Sin *leakage*: el OHE/escala se entrena **dentro** del CV vÃ­a `Pipeline`.

---

# ğŸ§ª Experimentos

## 1) PCA (proyecciÃ³n)

```python
from sklearn.model_selection import cross_validate

pca_levels = [0.80, 0.90, 0.95]
res_pca = []

for var in pca_levels:
    pipe = Pipeline([
        ("pre", pre),
        ("pca", PCA(n_components=var, svd_solver="full", random_state=RNG)),
        ("mdl", LinearRegression())
    ])
    cv = KFold(n_splits=5, shuffle=True, random_state=RNG)
    cvres = cross_validate(pipe, X, y, cv=cv,
                           scoring=("r2","neg_root_mean_squared_error"),
                           n_jobs=-1, return_estimator=False)
    res_pca.append({"variant": f"PCA@{int(var*100)}%",
                    "R2_mean": np.mean(cvres["test_r2"]),
                    "RMSE_mean": -np.mean(cvres["test_neg_root_mean_squared_error"])})
pd.DataFrame(res_pca)
```

## 2) Feature Selection â€” *Filter*

```python
fs_k = [10, 20, 40, 80]
res_filter = []

for score_func in [f_regression, mutual_info_regression]:
    for k in fs_k:
        fs = SelectKBest(score_func=score_func, k=k)
        pipe = Pipeline([("pre", pre),
                         ("fs", fs),
                         ("mdl", LinearRegression())])
        cv = KFold(n_splits=5, shuffle=True, random_state=RNG)
        cvres = cross_validate(pipe, X, y, cv=cv,
                               scoring=("r2","neg_root_mean_squared_error"),
                               n_jobs=-1)
        res_filter.append({"variant": f"FILTER-{score_func.__name__}-k={k}",
                           "R2_mean": np.mean(cvres["test_r2"]),
                           "RMSE_mean": -np.mean(cvres["test_neg_root_mean_squared_error"])})
pd.DataFrame(res_filter)
```

## 3) Feature Selection â€” *Wrapper (RFE)*

```python
res_rfe = []
for base_est in [LinearRegression(), RandomForestRegressor(n_estimators=200, random_state=RNG, n_jobs=-1)]:
    for k in [20, 40, 80]:
        fs = RFE(estimator=base_est, n_features_to_select=k, step=0.2)
        pipe = Pipeline([("pre", pre),
                         ("fs", fs),
                         ("mdl", LinearRegression())])
        cv = KFold(n_splits=5, shuffle=True, random_state=RNG)
        cvres = cross_validate(pipe, X, y, cv=cv,
                               scoring=("r2","neg_root_mean_squared_error"),
                               n_jobs=-1)
        res_rfe.append({"variant": f"RFE-{base_est.__class__.__name__}-k={k}",
                        "R2_mean": np.mean(cvres["test_r2"]),
                        "RMSE_mean": -np.mean(cvres["test_neg_root_mean_squared_error"])})
pd.DataFrame(res_rfe)
```

## 4) Feature Selection â€” *Embedded (Lasso path)*

```python
alphas = np.logspace(-4, 0, 8)
res_lasso = []

for a in alphas:
    pipe = Pipeline([("pre", pre),
                     ("mdl", Lasso(alpha=a, max_iter=20000, random_state=RNG))])
    cv = KFold(n_splits=5, shuffle=True, random_state=RNG)
    cvres = cross_validate(pipe, X, y, cv=cv,
                           scoring=("r2","neg_root_mean_squared_error"),
                           n_jobs=-1, return_estimator=True)
    res_lasso.append({"variant": f"LASSO@{a:.1e}",
                      "R2_mean": np.mean(cvres["test_r2"]),
                      "RMSE_mean": -np.mean(cvres["test_neg_root_mean_squared_error"])})
pd.DataFrame(res_lasso)
```

---

# ğŸ§· Estabilidad de selecciÃ³n (bootstrap)

```python
# Frecuencia con que cada feature (post-OHE) es seleccionada por Lasso
B = 30
freq = None
for b in range(B):
    Xtr, _, ytr, _ = train_test_split(X, y, test_size=0.3, random_state=RNG+b)
    pipe = Pipeline([("pre", pre), ("mdl", Lasso(alpha=1e-3, max_iter=20000, random_state=RNG))])
    pipe.fit(Xtr, ytr)
    # Obtener nombres post-preprocesamiento
    preproc = pipe.named_steps["pre"]
    num_names = num_cols
    cat_names = list(preproc.named_transformers_["cat"].named_steps["oh"].get_feature_names_out(cat_cols))
    all_names = num_names + cat_names
    coefs = pipe.named_steps["mdl"].coef_
    sel = (np.abs(coefs) > 0).astype(int)
    if freq is None:
        freq = pd.Series(sel, index=all_names, dtype=float)
    else:
        freq += pd.Series(sel, index=all_names, dtype=float)

stability = (freq / B).sort_values(ascending=False)
stability.head(30)
```

---

# ğŸ§ª Permutation importance en *holdâ€‘out*

```python
from sklearn.inspection import permutation_importance

Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=RNG)
best = Pipeline([("pre", pre),
                 ("mdl", RandomForestRegressor(n_estimators=400, random_state=RNG, n_jobs=-1))])
best.fit(Xtr, ytr)
perm = permutation_importance(best, Xte, yte, n_repeats=10, random_state=RNG, n_jobs=-1)
imp = pd.DataFrame({"feature": range(len(perm.importances_mean)),
                    "importance": perm.importances_mean}).sort_values("importance", ascending=False)
imp.head(25)
```

---

# ğŸ“Š Resumen comparativo

| Variante | RMSE (â†“) | RÂ² (â†‘) | Interpretabilidad | Costo (tiempo) | Notas |
|---|---:|---:|---|---|---|
| **PCA@80%** | **26 715** | **0.8850** | Baja (PCs) | **Bajo** | Equilibrio entre compresiÃ³n y rendimiento; apenas peor que 90% pero mÃ¡s liviano |
| **PCA@90%** | **26 662** | **0.8857** | Baja | **Medio** | Mejor RÂ² promedio y costo intermedio; *sweet spot* entre bias y varianza |
| **FILTER-MI k=40** | â€” | â€” | Media | Bajo | No ejecutado en el notebook actual; suele comportarse similar a PCA@80% con mayor explicabilidad |
| **RFE-LR k=40** | â€” | â€” | Alta | Alto | Wrapper iterativo, costoso; interpretabilidad mÃ¡xima si se usa con LR |
| **LASSO Î±=1e-3** | â€” | â€” | Alta (sparse) | Medio | Esperable RÂ²â‰ˆ0.88-0.89 y subset compacto de features (*OverallQual*, *GrLivArea*, etc.) |
| **RF + PermImp** | â€” | â€” | Media | Medio | Ãštil para validar relevancia de variables no lineales; sin fuga de datos |


---

# ğŸ§  DiscusiÃ³n

- **PCA 90â€“95%** suele dar el mejor **tradeâ€‘off**: reduce dimensionalidad fuerte manteniendo seÃ±al; evita multicolinealidad en `LinearRegression` y estabiliza el ajuste.  
- **Filter (SelectKBest)** es rÃ¡pido y transparente; con `mutual_info_regression` tenÃ©s sensibilidad no lineal, pero puede seleccionar redundantes si no combinÃ¡s con *wrapper*.  
- **RFE** mejora interpretabilidad (subset explÃ­cito), pero el **costo** crece (entrenamientos iterativos). Ãštil si querÃ©s **explicar** quÃ© columnas pesan.  
- **Lasso** entrega **sparsity** y ranking claro; en Ames, con OHE, suele concentrar seÃ±al en *OverallQual*, *GrLivArea*, *GarageCars/Area*, *TotalBsmtSF*, *1stFlrSF*, etc.  
- **Permutation importance (RF)** valida quÃ© variables importan en un modelo **no lineal** y ayuda a detectar *spurious* tras OHE.

---

# ğŸ”— ConexiÃ³n con otras unidades

- **UT2**: calidad y sesgos â†’ quÃ© variables son confiables antes de seleccionar.  
- **UT4**: *pipelines* y despliegue â†’ congelar *preprocess + selector + modelo*.  
- **UT5**: mÃ©tricas de negocio â†’ Â¿interpretabilidad > +0.01 de RÂ²?

---

# ğŸ§© ReflexiÃ³n final

ElegirÃ­a **Lasso** como selector primario: balancea rendimiento y explicabilidad y me deja un set compacto y defendible. Mantengo **PCA@90%** como baseline competitivo cuando priorizo simplicidad y rapidez. En revisiÃ³n, confirmo que no hay leakage y reporto `media Â± std` del CV.

---

# ğŸ§° Stack tÃ©cnico

**Lenguaje:** Python  
**LibrerÃ­as:** Pandas Â· NumPy Â· Scikitâ€‘learn Â· Matplotlib  
**Conceptos:** PCA Â· Filter/Wrapper/Embedded Â· Bootstrap Stability Â· Permutation Importance Â· KFold(5)

### ğŸ“ [Notebook](../../../notebooks/UT3-Extra.ipynb)

---

# ğŸ“š Referencias

- Scikitâ€‘learn: PCA, SelectKBest, RFE, Lasso, RandomForest, permutation_importance.  
- Domingos (2012). *A few useful things to know about ML*. CACM.  
- Kuhn & Johnson (2019). *Feature Engineering and Selection*.
